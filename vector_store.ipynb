{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamgodase2002/Generative-AI-/blob/main/vector_store.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5KrEb6vrkR"
      },
      "source": [
        "# Welcome to Colab!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JQesyTg7QSU-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a158ee95-5267-45dd-a2b3-7d10c6dc631e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is **Paris**.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import ai\n",
        "response = ai.generate_text(\"What is the capital of France?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-\""
      ],
      "metadata": {
        "id": "C5AWcEFkzw4f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall langchain langchain-openai langchain-core\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CpxkwIGyzxGf",
        "outputId": "be09a988-2281-4a16-a5be-1e0524c2995a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Using cached langchain-1.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langchain-openai\n",
            "  Using cached langchain_openai-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-core\n",
            "  Using cached langchain_core-1.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langgraph<1.1.0,>=1.0.2 (from langchain)\n",
            "  Using cached langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
            "  Using cached pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
            "Collecting openai<3.0.0,>=1.109.1 (from langchain-openai)\n",
            "  Using cached openai-2.8.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
            "  Using cached tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core)\n",
            "  Using cached langsmith-0.4.43-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting packaging<26.0.0,>=23.2.0 (from langchain-core)\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core)\n",
            "  Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core)\n",
            "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting typing-extensions<5.0.0,>=4.7.0 (from langchain-core)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core)\n",
            "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
            "  Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
            "  Using cached langgraph_prebuilt-1.0.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
            "  Using cached langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
            "  Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson>=3.9.14 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
            "  Using cached orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
            "  Using cached zstandard-0.25.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
            "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.10.0 (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
            "  Using cached jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting tqdm>4 (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Using cached pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai)\n",
            "  Using cached regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai)\n",
            "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting certifi (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core)\n",
            "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain)\n",
            "  Using cached ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core)\n",
            "  Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Using cached langchain-1.0.7-py3-none-any.whl (93 kB)\n",
            "Using cached langchain_openai-1.0.3-py3-none-any.whl (82 kB)\n",
            "Using cached langchain_core-1.0.5-py3-none-any.whl (471 kB)\n",
            "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Using cached langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
            "Using cached langsmith-0.4.43-py3-none-any.whl (410 kB)\n",
            "Using cached openai-2.8.0-py3-none-any.whl (1.0 MB)\n",
            "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Using cached pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
            "Using cached pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Using cached tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Using cached jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
            "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "Using cached langgraph_prebuilt-1.0.4-py3-none-any.whl (34 kB)\n",
            "Using cached langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "Using cached orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "Using cached regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
            "Using cached zstandard-0.25.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.5 MB)\n",
            "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
            "Using cached ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: zstandard, xxhash, urllib3, typing-extensions, tqdm, tenacity, sniffio, regex, pyyaml, packaging, ormsgpack, orjson, jsonpointer, jiter, idna, h11, distro, charset_normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, jsonpatch, httpcore, anyio, tiktoken, requests-toolbelt, pydantic, httpx, openai, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langchain\n",
            "  Attempting uninstall: zstandard\n",
            "    Found existing installation: zstandard 0.25.0\n",
            "    Uninstalling zstandard-0.25.0:\n",
            "      Successfully uninstalled zstandard-0.25.0\n",
            "  Attempting uninstall: xxhash\n",
            "    Found existing installation: xxhash 3.6.0\n",
            "    Uninstalling xxhash-3.6.0:\n",
            "      Successfully uninstalled xxhash-3.6.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.2\n",
            "    Uninstalling tenacity-9.1.2:\n",
            "      Successfully uninstalled tenacity-9.1.2\n",
            "  Attempting uninstall: sniffio\n",
            "    Found existing installation: sniffio 1.3.1\n",
            "    Uninstalling sniffio-1.3.1:\n",
            "      Successfully uninstalled sniffio-1.3.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2025.11.3\n",
            "    Uninstalling regex-2025.11.3:\n",
            "      Successfully uninstalled regex-2025.11.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.3\n",
            "    Uninstalling PyYAML-6.0.3:\n",
            "      Successfully uninstalled PyYAML-6.0.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: ormsgpack\n",
            "    Found existing installation: ormsgpack 1.12.0\n",
            "    Uninstalling ormsgpack-1.12.0:\n",
            "      Successfully uninstalled ormsgpack-1.12.0\n",
            "  Attempting uninstall: orjson\n",
            "    Found existing installation: orjson 3.11.4\n",
            "    Uninstalling orjson-3.11.4:\n",
            "      Successfully uninstalled orjson-3.11.4\n",
            "  Attempting uninstall: jsonpointer\n",
            "    Found existing installation: jsonpointer 3.0.0\n",
            "    Uninstalling jsonpointer-3.0.0:\n",
            "      Successfully uninstalled jsonpointer-3.0.0\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.12.0\n",
            "    Uninstalling jiter-0.12.0:\n",
            "      Successfully uninstalled jiter-0.12.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.16.0\n",
            "    Uninstalling h11-0.16.0:\n",
            "      Successfully uninstalled h11-0.16.0\n",
            "  Attempting uninstall: distro\n",
            "    Found existing installation: distro 1.9.0\n",
            "    Uninstalling distro-1.9.0:\n",
            "      Successfully uninstalled distro-1.9.0\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.4\n",
            "    Uninstalling charset-normalizer-3.4.4:\n",
            "      Successfully uninstalled charset-normalizer-3.4.4\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.11.12\n",
            "    Uninstalling certifi-2025.11.12:\n",
            "      Successfully uninstalled certifi-2025.11.12\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: typing-inspection\n",
            "    Found existing installation: typing-inspection 0.4.2\n",
            "    Uninstalling typing-inspection-0.4.2:\n",
            "      Successfully uninstalled typing-inspection-0.4.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.5\n",
            "    Uninstalling requests-2.32.5:\n",
            "      Successfully uninstalled requests-2.32.5\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.41.5\n",
            "    Uninstalling pydantic_core-2.41.5:\n",
            "      Successfully uninstalled pydantic_core-2.41.5\n",
            "  Attempting uninstall: jsonpatch\n",
            "    Found existing installation: jsonpatch 1.33\n",
            "    Uninstalling jsonpatch-1.33:\n",
            "      Successfully uninstalled jsonpatch-1.33\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.9\n",
            "    Uninstalling httpcore-1.0.9:\n",
            "      Successfully uninstalled httpcore-1.0.9\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.11.0\n",
            "    Uninstalling anyio-4.11.0:\n",
            "      Successfully uninstalled anyio-4.11.0\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.12.0\n",
            "    Uninstalling tiktoken-0.12.0:\n",
            "      Successfully uninstalled tiktoken-0.12.0\n",
            "  Attempting uninstall: requests-toolbelt\n",
            "    Found existing installation: requests-toolbelt 1.0.0\n",
            "    Uninstalling requests-toolbelt-1.0.0:\n",
            "      Successfully uninstalled requests-toolbelt-1.0.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.12.4\n",
            "    Uninstalling pydantic-2.12.4:\n",
            "      Successfully uninstalled pydantic-2.12.4\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.8.0\n",
            "    Uninstalling openai-2.8.0:\n",
            "      Successfully uninstalled openai-2.8.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.4.43\n",
            "    Uninstalling langsmith-0.4.43:\n",
            "      Successfully uninstalled langsmith-0.4.43\n",
            "  Attempting uninstall: langgraph-sdk\n",
            "    Found existing installation: langgraph-sdk 0.2.9\n",
            "    Uninstalling langgraph-sdk-0.2.9:\n",
            "      Successfully uninstalled langgraph-sdk-0.2.9\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.0.5\n",
            "    Uninstalling langchain-core-1.0.5:\n",
            "      Successfully uninstalled langchain-core-1.0.5\n",
            "  Attempting uninstall: langgraph-checkpoint\n",
            "    Found existing installation: langgraph-checkpoint 3.0.1\n",
            "    Uninstalling langgraph-checkpoint-3.0.1:\n",
            "      Successfully uninstalled langgraph-checkpoint-3.0.1\n",
            "  Attempting uninstall: langchain-openai\n",
            "    Found existing installation: langchain-openai 1.0.3\n",
            "    Uninstalling langchain-openai-1.0.3:\n",
            "      Successfully uninstalled langchain-openai-1.0.3\n",
            "  Attempting uninstall: langgraph-prebuilt\n",
            "    Found existing installation: langgraph-prebuilt 1.0.4\n",
            "    Uninstalling langgraph-prebuilt-1.0.4:\n",
            "      Successfully uninstalled langgraph-prebuilt-1.0.4\n",
            "  Attempting uninstall: langgraph\n",
            "    Found existing installation: langgraph 1.0.3\n",
            "    Uninstalling langgraph-1.0.3:\n",
            "      Successfully uninstalled langgraph-1.0.3\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 1.0.7\n",
            "    Uninstalling langchain-1.0.7:\n",
            "      Successfully uninstalled langchain-1.0.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\n",
            "google-adk 1.17.0 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed annotated-types-0.7.0 anyio-4.11.0 certifi-2025.11.12 charset_normalizer-3.4.4 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jiter-0.12.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-1.0.7 langchain-core-1.0.5 langchain-openai-1.0.3 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.4 langgraph-sdk-0.2.9 langsmith-0.4.43 openai-2.8.0 orjson-3.11.4 ormsgpack-1.12.0 packaging-25.0 pydantic-2.12.4 pydantic-core-2.41.5 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.12.0 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.5.0 xxhash-3.6.0 zstandard-0.25.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "annotated_types",
                  "anyio",
                  "certifi",
                  "distro",
                  "h11",
                  "httpcore",
                  "httpx",
                  "idna",
                  "jiter",
                  "jsonpatch",
                  "jsonpointer",
                  "langchain",
                  "langchain_core",
                  "langchain_openai",
                  "langsmith",
                  "openai",
                  "orjson",
                  "packaging",
                  "pydantic",
                  "regex",
                  "requests",
                  "requests_toolbelt",
                  "sniffio",
                  "tenacity",
                  "tiktoken",
                  "tiktoken_ext",
                  "tqdm",
                  "typing_inspection",
                  "urllib3",
                  "zstandard"
                ]
              },
              "id": "6d422f895b584dab90206db41d8e0448"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.vectorstores'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3938337676.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install --upgrade --force-reinstall langchain langchain-openai langchain-core'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChroma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.vectorstores'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Create LangChain documents for IPL players\n",
        "\n",
        "doc1 = Document(\n",
        "        page_content=\"Virat Kohli is one of the most successful and consistent batsmen in IPL history. Known for his aggressive batting style and fitness, he has led the Royal Challengers Bangalore in multiple seasons.\",\n",
        "        metadata={\"team\": \"Royal Challengers Bangalore\"}\n",
        "    )\n",
        "doc2 = Document(\n",
        "        page_content=\"Rohit Sharma is the most successful captain in IPL history, leading Mumbai Indians to five titles. He's known for his calm demeanor and ability to play big innings under pressure.\",\n",
        "        metadata={\"team\": \"Mumbai Indians\"}\n",
        "    )\n",
        "doc3 = Document(\n",
        "        page_content=\"MS Dhoni, famously known as Captain Cool, has led Chennai Super Kings to multiple IPL titles. His finishing skills, wicketkeeping, and leadership are legendary.\",\n",
        "        metadata={\"team\": \"Chennai Super Kings\"}\n",
        "    )\n",
        "doc4 = Document(\n",
        "        page_content=\"Jasprit Bumrah is considered one of the best fast bowlers in T20 cricket. Playing for Mumbai Indians, he is known for his yorkers and death-over expertise.\",\n",
        "        metadata={\"team\": \"Mumbai Indians\"}\n",
        "    )\n",
        "doc5 = Document(\n",
        "        page_content=\"Ravindra Jadeja is a dynamic all-rounder who contributes with both bat and ball. Representing Chennai Super Kings, his quick fielding and match-winning performances make him a key player.\",\n",
        "        metadata={\"team\": \"Chennai Super Kings\"}\n",
        "\n"
      ],
      "metadata": {
        "id": "1MrgRPa-zxd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [doc1, doc2, doc3, doc4, doc5]"
      ],
      "metadata": {
        "id": "Q-MP9Jkczxmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = Chroma(\n",
        "    embedding_function=OpenAIEmbeddings(),\n",
        "    persist_directory='my_chroma_db',\n",
        "    collection_name='sample'\n",
        ")"
      ],
      "metadata": {
        "id": "5JsEKK_nzxtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add documents\n",
        "vector_store.add_documents(docs)"
      ],
      "metadata": {
        "id": "KIJU74Sizx3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view documents\n",
        "vector_store.get(include=['embeddings','documents', 'metadatas'])"
      ],
      "metadata": {
        "id": "T-2j5j342mjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# search documents\n",
        "vector_store.similarity_search(\n",
        "    query='Who among these are a bowler?',\n",
        "    k=2\n",
        ")"
      ],
      "metadata": {
        "id": "pEl3dJhU2mv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# search with similarity score\n",
        "vector_store.similarity_search_with_score(\n",
        "    query='Who among these are a bowler?',\n",
        "    k=2\n",
        ")"
      ],
      "metadata": {
        "id": "IsPWH4qR2m4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# meta-data filtering\n",
        "vector_store.similarity_search_with_score(\n",
        "    query=\"\",\n",
        "    filter={\"team\": \"Chennai Super Kings\"}\n",
        ")"
      ],
      "metadata": {
        "id": "e2m5xb8x2nB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# update documents\n",
        "updated_doc1 = Document(\n",
        "    page_content=\"Virat Kohli, the former captain of Royal Challengers Bangalore (RCB), is renowned for his aggressive leadership and consistent batting performances. He holds the record for the most runs in IPL history, including multiple centuries in a single season. Despite RCB not winning an IPL title under his captaincy, Kohli's passion and fitness set a benchmark for the league. His ability to chase targets and anchor innings has made him one of the most dependable players in T20 cricket.\",\n",
        "    metadata={\"team\": \"Royal Challengers Bangalore\"}\n",
        ")\n",
        "\n",
        "vector_store.update_document(document_id='09a39dc6-3ba6-4ea7-927e-fdda591da5e4', document=updated_doc1)"
      ],
      "metadata": {
        "id": "8kuLF2uA2vlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view documents\n",
        "vector_store.get(include=['embeddings','documents', 'metadatas'])"
      ],
      "metadata": {
        "id": "AQrvikvm2vsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete document\n",
        "vector_store.delete(ids=['09a39dc6-3ba6-4ea7-927e-fdda591da5e4'])"
      ],
      "metadata": {
        "id": "XoAEt-vW2vy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view documents\n",
        "vector_store.get(include=['embeddings','documents', 'metadatas'])"
      ],
      "metadata": {
        "id": "uGI3uw782v4e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}